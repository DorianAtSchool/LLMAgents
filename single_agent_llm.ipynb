{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2824b7d852407cba1c30e1cd95848b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# huggingface login\n",
    "# Get your token from huggingface.co/settings/tokens\n",
    "from huggingface_hub import login\n",
    "login()  # This will prompt for your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outlines import models, generate\n",
    "# pip install outlines transformers datasets\n",
    "\n",
    "model = models.transformers(\"facebook/opt-iml-max-1.3b\")\n",
    "\n",
    "generator = generate.regex(\n",
    "    model,\n",
    "    r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the IP address of the Google DNS servers? \"\n",
    "answer = generator(prompt, max_tokens=30)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with 2 \"training\" and 1 \"test\"\n",
    "        #   - Certain times are completely unavailable (e.g., sleep, existing meetings).\n",
    "        #   - Some times are less ideal (e.g., early morning or late evening).\n",
    "        #   - Certain times are optimal for scheduling activities (e.g., typical work hours or daylight hours).\n",
    "\n",
    "        # You will be given some examples, and then a new context prompt. Your task is to generate a cost table for the new context prompt. Only return the array of numbers.\n",
    "\n",
    "        # param: *context_prompt*: includes existing meetings, preferences, and constraints\n",
    "\n",
    "    # prompt = \"\"\"\n",
    "\n",
    "    # TASK DESCRIPTION:\n",
    "    #     Generate 24-hour cost table that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "    #        - Certain times are completely unavailable (e.g., sleep, existing meetings).\n",
    "    #        - Some times are less ideal (e.g., early morning or late evening).\n",
    "    #        - Certain times are optimal for scheduling activities (e.g., typical work hours or daylight hours).\n",
    "\n",
    "    #      You will be given some examples, and then a new context prompt. Your task is to generate a cost table for the new context prompt. Only return the 24-hours cost table array of numbers.\n",
    "\n",
    "    #     param: *context_prompt*: includes existing meetings, preferences, and constraints\n",
    "    #     Examples:\n",
    "\n",
    "    # \"context_prompt\":\n",
    "    # \"From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\"\n",
    "    # \"goal\": \"Generate an array for a 24-hour cost table where each hour reflects its scheduling cost based on the constraints provided.\"\n",
    "    # ”cost_table”: [\n",
    "    #     1000, 1000, 1000, 1000, 1000, 1000, 1000,  # 12:00 AM to 6:59 AM\n",
    "    #     50, 50,  # 7:00 AM to 8:59 AM\n",
    "    #     float('inf'), float('inf'), float('inf'), float('inf'), float('inf'),  # 9:00 AM to 2:00 PM\n",
    "    #     0,  # 2:00 PM to 2:59 PM\n",
    "    #     float('inf'),  # 3:00 PM to 3:59 PM\n",
    "    #     0, 0, 0, 0, 0,  # 4:00 PM to 9:00 PM\n",
    "    #     500, 500, 500  # 9:01 PM to 11:59 PM\n",
    "    # ]\n",
    "\n",
    "    # \"context_prompt\":\n",
    "    # \"From 12:00 AM to 5:00 AM, scheduling soccer practice is unreasonable as it falls outside daylight hours, resulting in a high cost of 500. Between 5:01 AM and 7:00 AM, the early sunrise makes it less ideal, leading to a moderate cost of 100. From 7:01 AM to 4:00 PM, this time is available but not optimal, warranting a low-moderate cost of 50. The period from 4:00 PM to 5:59 PM is ideal for soccer practice, so the cost is 0. From 6:00 PM to 6:59 PM, the yoga class creates a scheduling conflict with an INFINITE cost. Finally, from 7:00 PM to 11:59 PM, scheduling falls outside preferred daylight hours, with a cost ranging linearly from 50 to 100.\"\n",
    "    # \"goal\": \"Generate an array for a 24-hour cost table where each hour reflects its scheduling cost based on the constraints provided.\"\n",
    "    # ”cost_table” : [\n",
    "    #     500, 500, 500, 500, 500,  # 12:00 AM to 5:00 AM\n",
    "    #     100, 100,  # 5:01 AM to 7:00 AM\n",
    "    #     50, 50, 50, 50, 50, 50, 50, 50, 50,  # 7:01 AM to 4:00 PM\n",
    "    #     0, 0,  # 4:00 PM to 5:59 PM\n",
    "    #     float('inf'),  # 6:00 PM to 6:59 PM\n",
    "    #     50, 62, 75, 87, 100  # 7:00 PM to 11:59 PM (linear increase)\n",
    "    # ]\n",
    "\n",
    "\n",
    "\n",
    "    # ]\n",
    "\n",
    "\n",
    "\n",
    "    # \"CONTEXT PROMPT\":\n",
    "    # \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a high cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "    # NEW GOAL: \"Generate an array for a 24-hour cost table where each hour reflects its scheduling cost based on the constraints provided.\"\n",
    "\n",
    "    # \"COST TABLE\" :[\n",
    "\n",
    "\n",
    "\n",
    "    # \"\"\"\n",
    "\n",
    "    # structured_prompt = f\"\"\"\n",
    "\n",
    "    #         Convert the following description to a Python list.\n",
    "    #         Format: [cost at hour 12:00AM-1:00AM, cost at hour 1:01AM-2:00AM, ..., cost at hour 10:01PM-11:00PM, cost at hour 11:01PMM-11:59PM]\n",
    "    #         Rules:\n",
    "    #         - Only return list of numbers\n",
    "    #         - List must have 24 items\n",
    "    #         - Match input constraints exactly\n",
    "\n",
    "\n",
    "    #         New Context Prompt:\n",
    "    #         [{prompt}] -> \n",
    "\n",
    "    #         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from outlines import models, generate\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from enum import Enum\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "\n",
    "# double_quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "\n",
    "\n",
    "class ForcedGeneration:\n",
    "   \n",
    "    def __init__(self, model):\n",
    "        self.openai = models.openai(\"gpt-4o\", api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "        self.llm = models.transformers(model)    \n",
    "        self.generator = generate.choice(self.llm, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.openaigenerator = generate.choice(self.openai, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.completed_json = {\n",
    "            \"12:00AM-12:59AM\": -1,\n",
    "            \"1:00AM-1:59AM\": -1,\n",
    "            \"2:00AM-2:59AM\": -1,\n",
    "            \"3:00AM-3:59AM\": -1,\n",
    "            \"4:00AM-4:59AM\": -1,\n",
    "            \"5:00AM-5:59AM\": -1,\n",
    "            \"6:00AM-6:59AM\": -1,\n",
    "            \"7:00AM-7:59AM\": -1,\n",
    "            \"8:00AM-8:59AM\": -1,\n",
    "            \"9:00AM-9:59AM\": -1,\n",
    "            \"10:00AM-10:59AM\": -1,\n",
    "            \"11:00AM-11:59AM\": -1,\n",
    "            \"12:00PM-12:59PM\": -1,\n",
    "            \"1:00PM-1:59PM\": -1,\n",
    "            \"2:00PM-2:59PM\": -1,\n",
    "            \"3:00PM-3:59PM\": -1,\n",
    "            \"4:00PM-4:59PM\": -1,\n",
    "            \"5:00PM-5:59PM\": -1,\n",
    "            \"6:00PM-6:59PM\": -1,\n",
    "            \"7:00PM-7:59PM\": -1,\n",
    "            \"8:00PM-8:59PM\": -1,\n",
    "            \"9:00PM-9:59PM\": -1,\n",
    "            \"10:00PM-10:59PM\": -1,\n",
    "            \"11:00PM-11:59PM\": -1\n",
    "        }\n",
    "        print(\"generator loaded\")\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "            # self.target_token_ids = [self.tokenizer.encode(token) for token in self.completed_array]\n",
    "    def gen_context(self, prompt, time):\n",
    "        return \"\"\"\n",
    "\n",
    "        \n",
    "        You are an intelligent assistant that determines the cost associated with scheduling activities for a specific hour of the day. Your task is to assess the given hour in context and assign a cost from the predefined options: [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "\n",
    "        Task Description:\n",
    "        Generate 24-hour cost table that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "        - Certain times are completely unavailable (e.g., sleep, existing meetings) which should have \"INFINITE\" cost.\n",
    "        - Some times are less ideal (e.g., early morning or late evening) which should have a cost of \"100\", \"500\", or \"1000\".\n",
    "        - Certain times are optimal for scheduling activities which should have a cost of 0.\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        Description:  From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 1:00AM-1:59AM\n",
    "        Output: \"1000\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\n",
    "        Specified Hour: 2:00PM-2:59PM  \n",
    "        Output: \"0\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 10:00PM-10:59PM  \n",
    "        Output: \"500\"  \n",
    "\n",
    "\n",
    "        \n",
    "        Given the following description, determine the cost for the specified hour:\n",
    "\n",
    "        Description: {prompt}  \n",
    "        Specified Hour: {time}  \n",
    "\n",
    "        # Hard Constraints:\n",
    "        1. Only select a cost from [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "        2. Always evaluate and assign a cost based on the specific hour, without inferring across multiple hours.\n",
    "        3. The output should only be the cost value in quotes.\n",
    "\n",
    "        Output:\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def call(self, prompt):\n",
    "        sentence_so_far = \"\"\n",
    "        keys = list(self.completed_json.keys())\n",
    "\n",
    "        for hour in keys:\n",
    "            # Add the current hour's description to the context\n",
    "            sentence_so_far = self.gen_context(prompt, hour)\n",
    "            gen = None\n",
    "            openai_gen = None\n",
    "            # Use the generator to compute the cost\n",
    "            try:\n",
    "                gen = self.generator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (Transformer): {gen}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error with Transformer generation: {e}\")\n",
    "                gen = \"500\"  # Fallback cost in case of error\n",
    "\n",
    "            try:\n",
    "                openai_gen = self.openaigenerator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (OpenAI): {openai_gen}\")\n",
    "                cost = int(openai_gen.strip())\n",
    "            except ValueError:\n",
    "                print(f\"Invalid cost generated by OpenAI: {openai_gen}. Defaulting to Transformer cost.\")\n",
    "                cost = int(gen.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"Error with OpenAI generation: {e}. Defaulting to 500.\")\n",
    "                cost = 500  # Fallback cost in case of error\n",
    "\n",
    "            # Save the generated cost for the current hour\n",
    "            self.completed_json[hour] = gen\n",
    "\n",
    "        # Return the completed JSON as a string\n",
    "        return json.dumps(self.completed_json, indent=4)\n",
    "        \n",
    "        # openai_gen = None\n",
    "        # i=0\n",
    "        # while i < 5:\n",
    "        #     i += 1\n",
    "        #     try:\n",
    "        #         openai_gen = self.openaigenerator(sentence_so_far, max_tokens=10)\n",
    "        #         break\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"Error with OpenAI generation: {e}\")\n",
    "        #         sentence_so_far += \"\\n Notice not to re-create the following error: \" + str(e)\n",
    "        #         print(i)\n",
    "        #         continue\n",
    "        \n",
    "        # if openai_gen is None:\n",
    "        #     print(\"OpenAI generation failed. Defaulting to 500.\")\n",
    "        #     openai_gen = \"500\"\n",
    "\n",
    "        return gen\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a high cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "\n",
    "    model = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "    # model = \"facebook/opt-iml-max-1.3b\"\n",
    "    gen = ForcedGeneration(model)\n",
    "    result = gen.call(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e7743be741408f9a25bd1fb62713d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator loaded\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 500\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 0\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n",
      "Generated (Transformer): 100\n",
      "Invalid cost generated by OpenAI: None. Defaulting to Transformer cost.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# model = \"facebook/opt-iml-max-1.3b\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m gen \u001b[38;5;241m=\u001b[39m ForcedGeneration(model)\n\u001b[1;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[1], line 107\u001b[0m, in \u001b[0;36mForcedGeneration.call\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Use the generator to compute the cost\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_so_far\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated (Transformer): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\outlines\\generate\\api.py:504\u001b[0m, in \u001b[0;36mSequenceGeneratorAdapter.__call__\u001b[1;34m(self, prompts, max_tokens, stop_at, seed, **model_specific_params)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt of list of prompts.\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m generation_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_generation_parameters(\n\u001b[0;32m    501\u001b[0m     max_tokens, stop_at, seed\n\u001b[0;32m    502\u001b[0m )\n\u001b[1;32m--> 504\u001b[0m completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_specific_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format(completions)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\outlines\\models\\transformers.py:247\u001b[0m, in \u001b[0;36mTransformers.generate\u001b[1;34m(self, prompts, generation_parameters, logits_processor, sampling_parameters)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    241\u001b[0m generation_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_generation_kwargs(\n\u001b[0;32m    242\u001b[0m     prompts,\n\u001b[0;32m    243\u001b[0m     generation_parameters,\n\u001b[0;32m    244\u001b[0m     logits_processor,\n\u001b[0;32m    245\u001b[0m     sampling_parameters,\n\u001b[0;32m    246\u001b[0m )\n\u001b[1;32m--> 247\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_output_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# if single str input and single sample per input, convert to a 1D output\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompts, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\outlines\\models\\transformers.py:350\u001b[0m, in \u001b[0;36mTransformers._generate_output_seq\u001b[1;34m(self, prompts, inputs, generation_config, **generation_kwargs)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_output_seq\u001b[39m(\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m, prompts, inputs, generation_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_kwargs\n\u001b[0;32m    348\u001b[0m ):\n\u001b[0;32m    349\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 350\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m     \u001b[38;5;66;03m# encoder-decoder returns output_ids only, decoder-only returns full seq ids\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2252\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2245\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2246\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2247\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2248\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2249\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2265\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2266\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2272\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3251\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3248\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[1;32m-> 3251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3252\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:1070\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep)\u001b[0m\n\u001b[0;32m   1067\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1070\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:795\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m    784\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    785\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    786\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m         cache_position,\n\u001b[0;32m    793\u001b[0m     )\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 795\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:543\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    542\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 543\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    546\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:160\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[1;34m(self, hidden_state)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(hidden_state)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\Documents\\RBR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Regex pattern to match an array of 24 numbers\n",
    "number_array_pattern = r'^\\s*\\[\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+))),\\s*(-?(?:\\d+\\.?\\d*|float\\(\\'inf\\'\\)|-?(?:\\.\\d+)))\\s*\\]$'\n",
    "\n",
    "# Function to validate the array\n",
    "def validate_number_array(array_string):\n",
    "    return re.match(number_array_pattern, array_string) is not None\n",
    "\n",
    "# Example usage\n",
    "examples = [\n",
    "    '[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]',\n",
    "    '[0.5, -1.2, float(\\'inf\\'), 3.14, -0.01, 100, 0, -99.99, float(\\'inf\\'), 42, 0.001, -0.1, 1000, -1000, 0.5, -0.5, 3.14159, -3.14159, 2.718, -2.718, 1.414, -1.414, 0.707, -0.707]',\n",
    "    '[-1, 2, float(\\'inf\\'), 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]'\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    print(f\"Validating: {example}\")\n",
    "    print(f\"Valid: {validate_number_array(example)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting outlines\n",
      "  Using cached outlines-0.1.10-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.45.0-py3-none-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting interegular (from outlines)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2 (from outlines)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting lark (from outlines)\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nest_asyncio (from outlines)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from outlines)\n",
      "  Downloading numpy-2.2.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.8/60.8 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting cloudpickle (from outlines)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting diskcache (from outlines)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting pydantic>=2.0 (from outlines)\n",
      "  Using cached pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting referencing (from outlines)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema (from outlines)\n",
      "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests (from outlines)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from outlines)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing_extensions (from outlines)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycountry (from outlines)\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines)\n",
      "  Using cached airportsdata-20241001-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting outlines_core==0.1.25 (from outlines)\n",
      "  Using cached outlines_core-0.1.25-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-18.1.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.10-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->outlines)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.0->outlines)\n",
      "  Using cached pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->outlines)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->outlines)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->outlines)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->outlines)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting colorama (from tqdm->outlines)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->outlines)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->outlines)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->outlines)\n",
      "  Using cached rpds_py-0.22.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Using cached outlines-0.1.10-py3-none-any.whl (87 kB)\n",
      "Using cached outlines_core-0.1.25-cp311-cp311-win_amd64.whl (243 kB)\n",
      "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached bitsandbytes-0.45.0-py3-none-win_amd64.whl (68.5 MB)\n",
      "Using cached torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.10-cp311-cp311-win_amd64.whl (442 kB)\n",
      "   ---------------------------------------- 0.0/442.3 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 133.1/442.3 kB 4.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 235.5/442.3 kB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 368.6/442.3 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 442.3/442.3 kB 2.8 MB/s eta 0:00:00\n",
      "Using cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading numpy-2.2.0-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/12.9 MB 4.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/12.9 MB 4.6 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.6/12.9 MB 4.8 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.8/12.9 MB 4.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/12.9 MB 4.9 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.4/12.9 MB 5.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 5.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 5.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.9 MB 5.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.3/12.9 MB 5.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.6/12.9 MB 5.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.8/12.9 MB 5.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.6/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.9/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.2/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.4/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.7/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.9/12.9 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.4/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.6/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.9 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.0/12.9 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.1/12.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.2/12.9 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.4/12.9 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.6/12.9 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.9/12.9 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.1/12.9 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.2/12.9 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.4/12.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.7/12.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.8/12.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.0/12.9 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.2/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.3/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.5/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.7/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.9/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.1/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.9/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.3/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.6/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.8/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.1/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.4/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.6/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.9/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.4/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.9/12.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Using cached pyarrow-18.1.0-cp311-cp311-win_amd64.whl (25.1 MB)\n",
      "Using cached pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Using cached pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "   ---------------------------------------- 0.0/162.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 162.0/162.0 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
      "   ---------------------------------------- 0.0/274.1 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 163.8/274.1 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 274.1/274.1 kB 5.7 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached airportsdata-20241001-py3-none-any.whl (912 kB)\n",
      "Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 88.5/88.5 kB 4.9 MB/s eta 0:00:00\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 5.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.4/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.7/1.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.9/1.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.3/1.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.7/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/11.6 MB 3.7 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/11.6 MB 3.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 4.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 4.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.7/11.6 MB 4.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/11.6 MB 4.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.2/11.6 MB 4.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.6 MB 4.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.7/11.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.0/11.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.2/11.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.5/11.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.0/11.6 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.3/11.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.6/11.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.2/11.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.4/11.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.6/11.6 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.6 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/11.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.2/11.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.4/11.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.3/11.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.4/11.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.5/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.7/11.6 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.1/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.6 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.6 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.2/11.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 4.8 MB/s eta 0:00:00\n",
      "Using cached pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "   ---------------------------------------- 0.0/167.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 167.3/167.3 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.8/101.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.6/51.6 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 358.4/536.2 kB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 536.2/536.2 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB ? eta 0:00:00\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "   ---------------------------------------- 0.0/508.0 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/508.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 122.9/508.0 kB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 368.6/508.0 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  501.8/508.0 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 508.0/508.0 kB 2.9 MB/s eta 0:00:00\n",
      "Using cached rpds_py-0.22.3-cp311-cp311-win_amd64.whl (231 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 0.0/346.6 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 235.5/346.6 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 346.6/346.6 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.3/126.3 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.0/91.0 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, mpmath, xxhash, urllib3, tzdata, typing_extensions, sympy, six, safetensors, rpds-py, regex, pyyaml, pycountry, pyarrow, propcache, packaging, numpy, networkx, nest_asyncio, multidict, MarkupSafe, lark, interegular, idna, fsspec, frozenlist, filelock, diskcache, dill, colorama, cloudpickle, charset-normalizer, certifi, attrs, annotated-types, airportsdata, aiohappyeyeballs, yarl, tqdm, requests, referencing, python-dateutil, pydantic-core, multiprocess, jinja2, aiosignal, torch, pydantic, pandas, jsonschema-specifications, huggingface-hub, aiohttp, tokenizers, jsonschema, bitsandbytes, transformers, outlines_core, datasets, outlines\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.7\n",
      "    Uninstalling pytz-2022.7:\n",
      "      Successfully uninstalled pytz-2022.7\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.2.1\n",
      "    Uninstalling mpmath-1.2.1:\n",
      "      Successfully uninstalled mpmath-1.2.1\n",
      "  Attempting uninstall: xxhash\n",
      "    Found existing installation: xxhash 3.5.0\n",
      "    Uninstalling xxhash-3.5.0:\n",
      "      Successfully uninstalled xxhash-3.5.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.5\n",
      "    Uninstalling safetensors-0.4.5:\n",
      "      Successfully uninstalled safetensors-0.4.5\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.22.3\n",
      "    Uninstalling rpds-py-0.22.3:\n",
      "      Successfully uninstalled rpds-py-0.22.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2022.7.9\n",
      "    Uninstalling regex-2022.7.9:\n",
      "      Successfully uninstalled regex-2022.7.9\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pycountry\n",
      "    Found existing installation: pycountry 24.6.1\n",
      "    Uninstalling pycountry-24.6.1:\n",
      "      Successfully uninstalled pycountry-24.6.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.0\n",
      "    Uninstalling packaging-23.0:\n",
      "      Successfully uninstalled packaging-23.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.8.4\n",
      "    Uninstalling networkx-2.8.4:\n",
      "      Successfully uninstalled networkx-2.8.4\n",
      "  Attempting uninstall: nest_asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.2\n",
      "    Uninstalling multidict-6.0.2:\n",
      "      Successfully uninstalled multidict-6.0.2\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.1\n",
      "    Uninstalling MarkupSafe-2.1.1:\n",
      "      Successfully uninstalled MarkupSafe-2.1.1\n",
      "  Attempting uninstall: lark\n",
      "    Found existing installation: lark 1.2.2\n",
      "    Uninstalling lark-1.2.2:\n",
      "      Successfully uninstalled lark-1.2.2\n",
      "  Attempting uninstall: interegular\n",
      "    Found existing installation: interegular 0.3.3\n",
      "    Uninstalling interegular-0.3.3:\n",
      "      Successfully uninstalled interegular-0.3.3\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.3.3\n",
      "    Uninstalling frozenlist-1.3.3:\n",
      "      Successfully uninstalled frozenlist-1.3.3\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.9.0\n",
      "    Uninstalling filelock-3.9.0:\n",
      "      Successfully uninstalled filelock-3.9.0\n",
      "  Attempting uninstall: diskcache\n",
      "    Found existing installation: diskcache 5.6.3\n",
      "    Uninstalling diskcache-5.6.3:\n",
      "      Successfully uninstalled diskcache-5.6.3\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.1\n",
      "    Uninstalling cloudpickle-2.2.1:\n",
      "      Successfully uninstalled cloudpickle-2.2.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.5.7\n",
      "    Uninstalling certifi-2023.5.7:\n",
      "      Successfully uninstalled certifi-2023.5.7\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 24.2.0\n",
      "    Uninstalling attrs-24.2.0:\n",
      "      Successfully uninstalled attrs-24.2.0\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "  Attempting uninstall: airportsdata\n",
      "    Found existing installation: airportsdata 20241001\n",
      "    Uninstalling airportsdata-20241001:\n",
      "      Successfully uninstalled airportsdata-20241001\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.8.1\n",
      "    Uninstalling yarl-1.8.1:\n",
      "      Successfully uninstalled yarl-1.8.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.35.1\n",
      "    Uninstalling referencing-0.35.1:\n",
      "      Successfully uninstalled referencing-0.35.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.1\n",
      "    Uninstalling pydantic_core-2.27.1:\n",
      "      Successfully uninstalled pydantic_core-2.27.1\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.2\n",
      "    Uninstalling Jinja2-3.1.2:\n",
      "      Successfully uninstalled Jinja2-3.1.2\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.2.0\n",
      "    Uninstalling aiosignal-1.2.0:\n",
      "      Successfully uninstalled aiosignal-1.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.3\n",
      "    Uninstalling pydantic-2.10.3:\n",
      "      Successfully uninstalled pydantic-2.10.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.26.5\n",
      "    Uninstalling huggingface-hub-0.26.5:\n",
      "      Successfully uninstalled huggingface-hub-0.26.5\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.3\n",
      "    Uninstalling aiohttp-3.8.3:\n",
      "      Successfully uninstalled aiohttp-3.8.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.17.3\n",
      "    Uninstalling jsonschema-4.17.3:\n",
      "      Successfully uninstalled jsonschema-4.17.3\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.45.0\n",
      "    Uninstalling bitsandbytes-0.45.0:\n",
      "      Successfully uninstalled bitsandbytes-0.45.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.0\n",
      "    Uninstalling transformers-4.47.0:\n",
      "      Successfully uninstalled transformers-4.47.0\n",
      "  Attempting uninstall: outlines_core\n",
      "    Found existing installation: outlines_core 0.1.25\n",
      "    Uninstalling outlines_core-0.1.25:\n",
      "      Successfully uninstalled outlines_core-0.1.25\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.2.0\n",
      "    Uninstalling datasets-3.2.0:\n",
      "      Successfully uninstalled datasets-3.2.0\n",
      "  Attempting uninstall: outlines\n",
      "    Found existing installation: outlines 0.1.10\n",
      "    Uninstalling outlines-0.1.10:\n",
      "      Successfully uninstalled outlines-0.1.10\n",
      "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 airportsdata-20241001 annotated-types-0.7.0 attrs-24.2.0 bitsandbytes-0.45.0 certifi-2024.8.30 charset-normalizer-3.4.0 cloudpickle-3.1.0 colorama-0.4.6 datasets-3.2.0 dill-0.3.8 diskcache-5.6.3 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.5 idna-3.10 interegular-0.3.3 jinja2-3.1.4 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 lark-1.2.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 nest_asyncio-1.6.0 networkx-3.4.2 numpy-2.2.0 outlines-0.1.10 outlines_core-0.1.25 packaging-24.2 pandas-2.2.3 propcache-0.2.1 pyarrow-18.1.0 pycountry-24.6.1 pydantic-2.10.3 pydantic-core-2.27.1 python-dateutil-2.9.0.post0 pytz-2024.2 pyyaml-6.0.2 referencing-0.35.1 regex-2024.11.6 requests-2.32.3 rpds-py-0.22.3 safetensors-0.4.5 six-1.17.0 sympy-1.13.1 tokenizers-0.21.0 torch-2.5.1 tqdm-4.67.1 transformers-4.47.0 typing_extensions-4.12.2 tzdata-2024.2 urllib3-2.2.3 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~afetensors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~egex'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~itsandbytes'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\~utlines_core'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "scikit-image 0.23.1 requires imageio>=2.33, but you have imageio 2.26.0 which is incompatible.\n",
      "scikit-image 0.23.1 requires lazy-loader>=0.4, but you have lazy-loader 0.2 which is incompatible.\n",
      "scikit-image 0.23.1 requires tifffile>=2022.8.12, but you have tifffile 2021.7.2 which is incompatible.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.3 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires python-dateutil==2.8.2, but you have python-dateutil 2.9.0.post0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires PyYAML==6.0, but you have pyyaml 6.0.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.0 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "s3fs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2024.9.0 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall outlines transformers datasets bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\dorian\\anaconda3\\lib\\site-packages (1.57.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\dorian\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dorian\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantized model\n",
    "\n",
    "import os\n",
    "import json\n",
    "from outlines import models, generate\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from enum import Enum\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''\n",
    "\n",
    "\n",
    "# double_quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True)\n",
    "\n",
    "class model_class:\n",
    "    def __init__(self, model_name):\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                device_map=\"auto\",\n",
    "                quantization_config=quantization_config,\n",
    "                # load_in_4bit=True,\n",
    "                torch_dtype=torch.float16,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "        self.model = model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "class ForcedGenerationQuantized:\n",
    "   \n",
    "    def __init__(self, model_name):\n",
    "        self.openai = models.openai(\"gpt-4o\", api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "        model = model_class(model_name)\n",
    "        self.llm = models.transformers(model)    \n",
    "        self.generator = generate.choice(self.llm, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.openaigenerator = generate.choice(self.openai, [\"500\", \"0\", \"1000\", \"INFINITE\", \"100\"])\n",
    "        self.completed_json = {\n",
    "            \"12:00AM-12:59AM\": -1,\n",
    "            \"1:00AM-1:59AM\": -1,\n",
    "            \"2:00AM-2:59AM\": -1,\n",
    "            \"3:00AM-3:59AM\": -1,\n",
    "            \"4:00AM-4:59AM\": -1,\n",
    "            \"5:00AM-5:59AM\": -1,\n",
    "            \"6:00AM-6:59AM\": -1,\n",
    "            \"7:00AM-7:59AM\": -1,\n",
    "            \"8:00AM-8:59AM\": -1,\n",
    "            \"9:00AM-9:59AM\": -1,\n",
    "            \"10:00AM-10:59AM\": -1,\n",
    "            \"11:00AM-11:59AM\": -1,\n",
    "            \"12:00PM-12:59PM\": -1,\n",
    "            \"1:00PM-1:59PM\": -1,\n",
    "            \"2:00PM-2:59PM\": -1,\n",
    "            \"3:00PM-3:59PM\": -1,\n",
    "            \"4:00PM-4:59PM\": -1,\n",
    "            \"5:00PM-5:59PM\": -1,\n",
    "            \"6:00PM-6:59PM\": -1,\n",
    "            \"7:00PM-7:59PM\": -1,\n",
    "            \"8:00PM-8:59PM\": -1,\n",
    "            \"9:00PM-9:59PM\": -1,\n",
    "            \"10:00PM-10:59PM\": -1,\n",
    "            \"11:00PM-11:59PM\": -1\n",
    "        }\n",
    "        print(\"generator loaded\")\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "            # self.target_token_ids = [self.tokenizer.encode(token) for token in self.completed_array]\n",
    "    def gen_context(self, prompt, time):\n",
    "        return \"\"\"\n",
    "\n",
    "        \n",
    "        You are an intelligent assistant that determines the cost associated with scheduling activities for a specific hour of the day. Your task is to assess the given hour in context and assign a cost from the predefined options: [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "\n",
    "        Task Description:\n",
    "        Generate 24-hour cost table that aligns with natural language constraints and preferences for scheduling activities.\n",
    "\n",
    "        - Certain times are completely unavailable (e.g., sleep, existing meetings) which should have \"INFINITE\" cost.\n",
    "        - Some times are less ideal (e.g., early morning or late evening) which should have a cost of \"100\", \"500\", or \"1000\".\n",
    "        - Certain times are optimal for scheduling activities which should have a cost of 0.\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        Description:  From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 1:00AM-1:59AM\n",
    "        Output: \"1000\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.\n",
    "        Specified Hour: 2:00PM-2:59PM  \n",
    "        Output: \"0\"  \n",
    "\n",
    "        Description: From 12:00 AM to 6:59 AM, scheduling is unreasonable due to a preference against early appointments, so this time has a very high cost of 1000. From 7:00 AM to 8:59 AM, the time is available but less ideal, warranting a moderate cost of 50. From 9:00 AM to 2:00 PM, work constraints render these times unavailable with an INFINITE cost. Between 2:00 PM and 2:59 PM, this period is flexible and ideal for the doctor's appointment, so it has a cost of 0. From 3:00 PM to 3:59 PM, the dentist appointment makes this hour unavailable with an INFINITE cost. From 4:00 PM to 9:00 PM, scheduling is optimal, also with a cost of 0. Finally, from 9:01 PM to 11:59 PM, late hours are less preferable and have a high cost of 500.  \n",
    "        Specified Hour: 10:00PM-10:59PM  \n",
    "        Output: \"500\"  \n",
    "\n",
    "\n",
    "        \n",
    "        Given the following description, determine the cost for the specified hour:\n",
    "\n",
    "        Description: {prompt}  \n",
    "        Specified Hour: {time}  \n",
    "\n",
    "        # Hard Constraints:\n",
    "        1. Only select a cost from [\"0\", \"100\", \"500\", \"1000\", \"INFINITE\"].\n",
    "        2. Always evaluate and assign a cost based on the specific hour, without inferring across multiple hours.\n",
    "        3. The output should only be the cost value in quotes.\n",
    "\n",
    "        Output:\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def call(self, prompt):\n",
    "        sentence_so_far = \"\"\n",
    "        keys = list(self.completed_json.keys())\n",
    "\n",
    "        for hour in keys:\n",
    "            # Add the current hour's description to the context\n",
    "            sentence_so_far = self.gen_context(prompt, hour)\n",
    "            gen = None\n",
    "            openai_gen = None\n",
    "            # Use the generator to compute the cost\n",
    "            try:\n",
    "                gen = self.generator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (Transformer): {gen}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error with Transformer generation: {e}\")\n",
    "                gen = \"500\"  # Fallback cost in case of error\n",
    "\n",
    "            try:\n",
    "                openai_gen = self.openaigenerator(sentence_so_far, max_tokens=3)\n",
    "                print(f\"Generated (OpenAI): {openai_gen}\")\n",
    "                cost = int(openai_gen.strip())\n",
    "            except ValueError:\n",
    "                print(f\"Invalid cost generated by OpenAI: {openai_gen}. Defaulting to Transformer cost.\")\n",
    "                cost = int(gen.strip())\n",
    "            except Exception as e:\n",
    "                print(f\"Error with OpenAI generation: {e}. Defaulting to 500.\")\n",
    "                cost = 500  # Fallback cost in case of error\n",
    "\n",
    "            # Save the generated cost for the current hour\n",
    "            self.completed_json[hour] = gen\n",
    "\n",
    "        # Return the completed JSON as a string\n",
    "        return json.dumps(self.completed_json, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    prompt = \"From 12:00 AM to 7:59 AM, these hours are available but less ideal for a doctor's appointment, resulting in a high cost of 200. Between 8:00 AM and 11:59 AM, work constraints render scheduling impossible, with an INFINITE cost. From 12:00 PM to 12:59 PM, this hour is optimal for a doctor's appointment, with a cost of 0. Between 1:00 PM and 4:59 PM, work hours make scheduling unavailable, resulting in an INFINITE cost. From 5:00 PM to 8:59 PM, this period is flexible and available, so the cost is 0. Finally, from 9:00 PM to 11:59 PM, late hours are less ideal for a doctor's appointment, resulting in a high cost of 500.\"\n",
    "    model = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "    # model = \"facebook/opt-iml-max-1.3b\"\n",
    "    gen = ForcedGenerationQuantized(model)\n",
    "    result = gen.call(prompt)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceH4/zephyr-7b-alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# model = \"facebook/opt-iml-max-1.3b\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m gen \u001b[38;5;241m=\u001b[39m ForcedGenerationQuantized(model)\n\u001b[0;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39mcall(prompt)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[1;32mIn[17], line 41\u001b[0m, in \u001b[0;36mForcedGenerationQuantized.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mopenai(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 41\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class(model_name)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mtransformers(model)    \n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m generate\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1000\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINFINITE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m, in \u001b[0;36mmodel_class.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m     20\u001b[0m     quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m     21\u001b[0m         load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m         bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[0;32m     23\u001b[0m     )\n\u001b[1;32m---> 24\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     25\u001b[0m             model_name,\n\u001b[0;32m     26\u001b[0m             device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m             quantization_config\u001b[38;5;241m=\u001b[39mquantization_config,\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;66;03m# load_in_4bit=True,\u001b[39;00m\n\u001b[0;32m     29\u001b[0m             torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m     30\u001b[0m             trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     33\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3669\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3666\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3669\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mvalidate_environment(\n\u001b[0;32m   3670\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype,\n\u001b[0;32m   3671\u001b[0m         from_tf\u001b[38;5;241m=\u001b[39mfrom_tf,\n\u001b[0;32m   3672\u001b[0m         from_flax\u001b[38;5;241m=\u001b[39mfrom_flax,\n\u001b[0;32m   3673\u001b[0m         device_map\u001b[38;5;241m=\u001b[39mdevice_map,\n\u001b[0;32m   3674\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[0;32m   3675\u001b[0m     )\n\u001b[0;32m   3676\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3677\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:82\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[0;32m     81\u001b[0m bnb_multibackend_is_enabled \u001b[38;5;241m=\u001b[39m is_bitsandbytes_multi_backend_available()\n\u001b[1;32m---> 82\u001b[0m validate_bnb_backend_availability(raise_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:558\u001b[0m, in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_cuda_backend_availability(raise_exception)\n",
      "File \u001b[1;32mc:\\Users\\Dorian\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:536\u001b[0m, in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[0;32m    535\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(log_msg)\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[0;32m    538\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(log_msg)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
